{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Jmf36jGZ1I",
        "outputId": "c9b8384c-dff4-47bb-f84f-c00025fa0bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) model that is trained on a massive amount of text data to generate language understanding and generation capabilities. These models are designed to process and analyze large amounts of natural language data, such as text from the internet, books, and other sources.\n",
            "\n",
            "LLMs are typically based on deep learning architectures, such as recurrent neural networks (RNNs) or transformers, which allow them to learn complex patterns and relationships in language data. They are trained on vast amounts of text data, often using unsupervised learning methods, to learn to predict the next word in a sequence of text given the context of the previous words.\n",
            "\n",
            "Some key characteristics of Large Language Models include:\n",
            "\n",
            "1. **Scalability**: LLMs are designed to handle large amounts of data and can be trained on massive datasets.\n",
            "2. **Contextual understanding**: LLMs can understand the context in which a word or phrase is used, allowing them to generate more accurate and relevant text.\n",
            "3. **Generation capabilities**: LLMs can generate human-like text, including articles, stories, and even entire books.\n",
            "4. **Fine-tuning**: LLMs can be fine-tuned for specific tasks, such as language translation, text summarization, or sentiment analysis.\n",
            "\n",
            "Examples of Large Language Models include:\n",
            "\n",
            "1. **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google, BERT is a powerful language model that has achieved state-of-the-art results in a wide range of natural language processing (NLP) tasks.\n",
            "2. **RoBERTa (Robustly Optimized BERT Pretraining Approach)**: Developed by Facebook AI, RoBERTa is a variant of BERT that uses a different approach to pre-training and has achieved even better results in some NLP tasks.\n",
            "3. **Transformer-XL**: Developed by the University of California, Berkeley, Transformer-XL is a large language model that uses a novel architecture to process longer input sequences and achieve better results in some NLP tasks.\n",
            "\n",
            "Large Language Models have many applications, including:\n",
            "\n",
            "1. **Language translation**: LLMs can be fine-tuned for language translation tasks, allowing them to generate accurate translations of text from one language to another.\n",
            "2. **Text summarization**: LLMs can be used to summarize long pieces of text, such as articles or documents, into shorter summaries.\n",
            "3. **Chatbots and virtual assistants**: LLMs can be used to generate responses to user input, allowing chatbots and virtual assistants to have more natural and human-like conversations.\n",
            "4. **Content generation**: LLMs can be used to generate content, such as articles, social media posts, and even entire books.\n",
            "\n",
            "Overall, Large Language Models have the potential to revolutionize the way we interact with language and have many exciting applications in areas such as natural language processing, machine learning, and artificial intelligence."
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"API KEY\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"What is Large Language Model?\"}],\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "O4w2WoFUGr4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0T8krXSEGmtH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}